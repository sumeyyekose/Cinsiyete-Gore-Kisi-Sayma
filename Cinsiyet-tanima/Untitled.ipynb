{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial parameters\n",
    "epochs = 200\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "img_dims = (96,96,3)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# load image files from the dataset\n",
    "image_files = [f for f in glob.glob('yuz_veriseti' + \"/**/*\", recursive=True) if not os.path.isdir(f)]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# converting images to arrays and labelling the categories\n",
    "for img in image_files:\n",
    "\n",
    "    image = cv2.imread(img)\n",
    "    \n",
    "    image = cv2.resize(image, (img_dims[0],img_dims[1]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    label = img.split(os.path.sep)[-2] # C:\\Files\\gender_dataset_face\\woman\\face_1162.jpg\n",
    "    if label == \"woman\":\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "        \n",
    "    labels.append([label]) # [[1], [0], [0], ...]\n",
    "\n",
    "# pre-processing\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# split dataset for training and validation\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "trainY = to_categorical(trainY, num_classes=2) # [[1, 0], [0, 1], [0, 1], ...]\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "# augmenting datset \n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define model\n",
    "def build(width, height, depth, classes):\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\": #Returns a string, either 'channels_first' or 'channels_last'\n",
    "        inputShape = (depth, height, width)\n",
    "        chanDim = 1\n",
    "    \n",
    "    # The axis that should be normalized, after a Conv2D layer with data_format=\"channels_first\", \n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = build(width=img_dims[0], height=img_dims[1], depth=img_dims[2],\n",
    "                            classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 96, 96, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 2050      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 8,675,202\n",
      "Trainable params: 8,672,322\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.7479 - accuracy: 0.7355 - val_loss: 0.7242 - val_accuracy: 0.5043\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 43s 2s/step - loss: 0.5177 - accuracy: 0.8012 - val_loss: 1.5347 - val_accuracy: 0.5043\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 44s 2s/step - loss: 0.4302 - accuracy: 0.8383 - val_loss: 0.7559 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.4149 - accuracy: 0.8467 - val_loss: 0.6959 - val_accuracy: 0.5065\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 45s 2s/step - loss: 0.3630 - accuracy: 0.8579 - val_loss: 1.3024 - val_accuracy: 0.5043\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 49s 2s/step - loss: 0.3157 - accuracy: 0.8832 - val_loss: 1.7034 - val_accuracy: 0.5043\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.2899 - accuracy: 0.8916 - val_loss: 2.1803 - val_accuracy: 0.5043\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 43s 2s/step - loss: 0.2742 - accuracy: 0.8989 - val_loss: 1.6211 - val_accuracy: 0.5043\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.2631 - accuracy: 0.8967 - val_loss: 1.7918 - val_accuracy: 0.5043\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.2382 - accuracy: 0.9147 - val_loss: 1.4768 - val_accuracy: 0.5173\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 42s 1s/step - loss: 0.2356 - accuracy: 0.9124 - val_loss: 0.4375 - val_accuracy: 0.7965\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.2185 - accuracy: 0.9107 - val_loss: 0.6659 - val_accuracy: 0.6883\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 52s 2s/step - loss: 0.1794 - accuracy: 0.9298 - val_loss: 0.5804 - val_accuracy: 0.7771\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.1947 - accuracy: 0.9220 - val_loss: 0.1672 - val_accuracy: 0.9242\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 42s 1s/step - loss: 0.1622 - accuracy: 0.9408 - val_loss: 0.1793 - val_accuracy: 0.9221\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.1461 - accuracy: 0.9431 - val_loss: 0.2593 - val_accuracy: 0.9026\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.1418 - accuracy: 0.9489 - val_loss: 0.2439 - val_accuracy: 0.8983\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.1344 - accuracy: 0.9436 - val_loss: 0.1647 - val_accuracy: 0.9264\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.1739 - accuracy: 0.9349 - val_loss: 0.2556 - val_accuracy: 0.9048\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.1202 - accuracy: 0.9551 - val_loss: 0.4578 - val_accuracy: 0.8442\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.1208 - accuracy: 0.9523 - val_loss: 0.6029 - val_accuracy: 0.8009\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.1103 - accuracy: 0.9545 - val_loss: 0.3531 - val_accuracy: 0.9589\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.1181 - accuracy: 0.9556 - val_loss: 0.0669 - val_accuracy: 0.9610\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.1140 - accuracy: 0.9601 - val_loss: 0.2053 - val_accuracy: 0.9221\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.1284 - accuracy: 0.9556 - val_loss: 0.0997 - val_accuracy: 0.9697\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.1166 - accuracy: 0.9593 - val_loss: 1.1307 - val_accuracy: 0.7143\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.1085 - accuracy: 0.9568 - val_loss: 1.0342 - val_accuracy: 0.7143\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.1438 - accuracy: 0.9481 - val_loss: 0.5846 - val_accuracy: 0.7965\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.1014 - accuracy: 0.9635 - val_loss: 0.7524 - val_accuracy: 0.7814\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0996 - accuracy: 0.9607 - val_loss: 0.1279 - val_accuracy: 0.9502\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 44s 2s/step - loss: 0.0956 - accuracy: 0.9590 - val_loss: 0.0647 - val_accuracy: 0.9740\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 42s 2s/step - loss: 0.0657 - accuracy: 0.9781 - val_loss: 0.0763 - val_accuracy: 0.9697\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 43s 2s/step - loss: 0.0828 - accuracy: 0.9686 - val_loss: 0.1303 - val_accuracy: 0.9545\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.0862 - accuracy: 0.9686 - val_loss: 0.1511 - val_accuracy: 0.9567\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0840 - accuracy: 0.9674 - val_loss: 0.1624 - val_accuracy: 0.9394\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0966 - accuracy: 0.9621 - val_loss: 0.2339 - val_accuracy: 0.9264\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0872 - accuracy: 0.9657 - val_loss: 0.4839 - val_accuracy: 0.8550\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0910 - accuracy: 0.9613 - val_loss: 0.2052 - val_accuracy: 0.9351\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0756 - accuracy: 0.9759 - val_loss: 0.0795 - val_accuracy: 0.9719\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0906 - accuracy: 0.9691 - val_loss: 0.2140 - val_accuracy: 0.9372\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.0822 - accuracy: 0.9702 - val_loss: 0.2008 - val_accuracy: 0.9286\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0849 - accuracy: 0.9686 - val_loss: 0.0842 - val_accuracy: 0.9805\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0797 - accuracy: 0.9714 - val_loss: 0.1049 - val_accuracy: 0.9589\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0769 - accuracy: 0.9714 - val_loss: 0.1073 - val_accuracy: 0.9524\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0756 - accuracy: 0.9730 - val_loss: 0.0567 - val_accuracy: 0.9784\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0644 - accuracy: 0.9719 - val_loss: 0.4897 - val_accuracy: 0.8766\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0855 - accuracy: 0.9708 - val_loss: 0.1737 - val_accuracy: 0.9567\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0777 - accuracy: 0.9702 - val_loss: 0.7499 - val_accuracy: 0.8268\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0652 - accuracy: 0.9775 - val_loss: 0.0860 - val_accuracy: 0.9740\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0779 - accuracy: 0.9674 - val_loss: 0.1890 - val_accuracy: 0.9437\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.0750 - accuracy: 0.9688 - val_loss: 0.1514 - val_accuracy: 0.9481\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.0552 - accuracy: 0.9787 - val_loss: 0.3349 - val_accuracy: 0.9004\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0568 - accuracy: 0.9843 - val_loss: 0.5237 - val_accuracy: 0.8593\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0529 - accuracy: 0.9820 - val_loss: 0.2269 - val_accuracy: 0.9264\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.0702 - accuracy: 0.9736 - val_loss: 0.1374 - val_accuracy: 0.9740\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0616 - accuracy: 0.9787 - val_loss: 0.0968 - val_accuracy: 0.9589\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0765 - accuracy: 0.9691 - val_loss: 0.1298 - val_accuracy: 0.9654\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0722 - accuracy: 0.9736 - val_loss: 0.1710 - val_accuracy: 0.9437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0809 - accuracy: 0.9686 - val_loss: 0.0605 - val_accuracy: 0.9805\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0553 - accuracy: 0.9787 - val_loss: 0.2545 - val_accuracy: 0.9113\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0631 - accuracy: 0.9747 - val_loss: 0.2719 - val_accuracy: 0.9307\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0588 - accuracy: 0.9775 - val_loss: 0.0522 - val_accuracy: 0.9719\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0464 - accuracy: 0.9809 - val_loss: 0.0365 - val_accuracy: 0.9870\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0514 - accuracy: 0.9803 - val_loss: 0.2190 - val_accuracy: 0.9481\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0615 - accuracy: 0.9770 - val_loss: 0.2147 - val_accuracy: 0.9394\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0550 - accuracy: 0.9803 - val_loss: 0.2544 - val_accuracy: 0.9242\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.0459 - accuracy: 0.9820 - val_loss: 0.1546 - val_accuracy: 0.9459\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0471 - accuracy: 0.9843 - val_loss: 0.0619 - val_accuracy: 0.9784\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0438 - accuracy: 0.9809 - val_loss: 0.0844 - val_accuracy: 0.9654\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0494 - accuracy: 0.9781 - val_loss: 0.1364 - val_accuracy: 0.9567\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0639 - accuracy: 0.9815 - val_loss: 0.4884 - val_accuracy: 0.8571\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0408 - accuracy: 0.9803 - val_loss: 0.1561 - val_accuracy: 0.9589\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0527 - accuracy: 0.9803 - val_loss: 0.1186 - val_accuracy: 0.9697\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0474 - accuracy: 0.9809 - val_loss: 0.1421 - val_accuracy: 0.9524\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0392 - accuracy: 0.9854 - val_loss: 0.0703 - val_accuracy: 0.9719\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0319 - accuracy: 0.9888 - val_loss: 0.0734 - val_accuracy: 0.9740\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 43s 2s/step - loss: 0.0287 - accuracy: 0.9893 - val_loss: 0.1214 - val_accuracy: 0.9610\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 0.1551 - val_accuracy: 0.9372\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 0.0974 - val_accuracy: 0.9675\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 41s 1s/step - loss: 0.0497 - accuracy: 0.9805 - val_loss: 0.1544 - val_accuracy: 0.9567\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0370 - accuracy: 0.9899 - val_loss: 0.0841 - val_accuracy: 0.9697\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0531 - accuracy: 0.9803 - val_loss: 0.1960 - val_accuracy: 0.9437\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0540 - accuracy: 0.9798 - val_loss: 0.1810 - val_accuracy: 0.9524\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0673 - accuracy: 0.9719 - val_loss: 0.2195 - val_accuracy: 0.9459\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0485 - accuracy: 0.9815 - val_loss: 0.3177 - val_accuracy: 0.9177\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0413 - accuracy: 0.9837 - val_loss: 0.1332 - val_accuracy: 0.9589\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 42s 1s/step - loss: 0.0356 - accuracy: 0.9860 - val_loss: 0.4130 - val_accuracy: 0.9004\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.1175 - val_accuracy: 0.9545\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 39s 1s/step - loss: 0.0453 - accuracy: 0.9832 - val_loss: 0.1557 - val_accuracy: 0.9567\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0275 - accuracy: 0.9888 - val_loss: 0.0873 - val_accuracy: 0.9762\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 40s 1s/step - loss: 0.0400 - accuracy: 0.9792 - val_loss: 0.0729 - val_accuracy: 0.9719\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 42s 2s/step - loss: 0.0400 - accuracy: 0.9848 - val_loss: 1.1371 - val_accuracy: 0.7771\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 50s 2s/step - loss: 0.0661 - accuracy: 0.9764 - val_loss: 0.3982 - val_accuracy: 0.8788\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0596 - accuracy: 0.9764 - val_loss: 0.1208 - val_accuracy: 0.9589\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0690 - accuracy: 0.9770 - val_loss: 1.0690 - val_accuracy: 0.7857\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0667 - accuracy: 0.9759 - val_loss: 0.2057 - val_accuracy: 0.9351\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 45s 2s/step - loss: 0.0449 - accuracy: 0.9815 - val_loss: 0.0967 - val_accuracy: 0.9697\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0869 - accuracy: 0.9680 - val_loss: 0.2833 - val_accuracy: 0.9286\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.1029 - accuracy: 0.9657 - val_loss: 0.2784 - val_accuracy: 0.9459\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 49s 2s/step - loss: 0.0780 - accuracy: 0.9725 - val_loss: 0.1595 - val_accuracy: 0.9654\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0578 - accuracy: 0.9803 - val_loss: 0.4466 - val_accuracy: 0.8896\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0647 - accuracy: 0.9764 - val_loss: 0.1107 - val_accuracy: 0.9610\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0614 - accuracy: 0.9809 - val_loss: 0.1372 - val_accuracy: 0.9502\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0617 - accuracy: 0.9775 - val_loss: 0.3211 - val_accuracy: 0.9264\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0548 - accuracy: 0.9770 - val_loss: 0.1285 - val_accuracy: 0.9632\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0423 - accuracy: 0.9854 - val_loss: 0.1570 - val_accuracy: 0.9654\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0521 - accuracy: 0.9815 - val_loss: 0.0976 - val_accuracy: 0.9805\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.0874 - val_accuracy: 0.9719\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0336 - accuracy: 0.9899 - val_loss: 0.0727 - val_accuracy: 0.9740\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 0.1537 - val_accuracy: 0.9697\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0407 - accuracy: 0.9860 - val_loss: 0.2391 - val_accuracy: 0.9372\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0392 - accuracy: 0.9893 - val_loss: 0.1162 - val_accuracy: 0.9675\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.1077 - val_accuracy: 0.9697\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0308 - accuracy: 0.9871 - val_loss: 0.1344 - val_accuracy: 0.9632\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 51s 2s/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0824 - val_accuracy: 0.9675\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 51s 2s/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.3859 - val_accuracy: 0.9199\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0359 - accuracy: 0.9876 - val_loss: 0.0672 - val_accuracy: 0.9805\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 45s 2s/step - loss: 0.0279 - accuracy: 0.9876 - val_loss: 0.1351 - val_accuracy: 0.9610\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 52s 2s/step - loss: 0.0438 - accuracy: 0.9848 - val_loss: 0.0801 - val_accuracy: 0.9740\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0326 - accuracy: 0.9876 - val_loss: 0.0996 - val_accuracy: 0.9697\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 53s 2s/step - loss: 0.0267 - accuracy: 0.9910 - val_loss: 0.1093 - val_accuracy: 0.9654\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0464 - accuracy: 0.9815 - val_loss: 0.3714 - val_accuracy: 0.9026\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0553 - accuracy: 0.9787 - val_loss: 2.7633 - val_accuracy: 0.6385\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 56s 2s/step - loss: 0.0517 - accuracy: 0.9803 - val_loss: 0.0946 - val_accuracy: 0.9675\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0379 - accuracy: 0.9865 - val_loss: 0.1030 - val_accuracy: 0.9632\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 46s 2s/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.0640 - val_accuracy: 0.9827\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 45s 2s/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.1372 - val_accuracy: 0.9632\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 45s 2s/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0685 - val_accuracy: 0.9762\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 50s 2s/step - loss: 0.0261 - accuracy: 0.9899 - val_loss: 0.0924 - val_accuracy: 0.9784\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 60s 2s/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.3924 - val_accuracy: 0.9156\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 67s 2s/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.0641 - val_accuracy: 0.9805\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 55s 2s/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.1843 - val_accuracy: 0.9524\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0327 - accuracy: 0.9876 - val_loss: 1.8068 - val_accuracy: 0.7403\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 52s 2s/step - loss: 0.0424 - accuracy: 0.9832 - val_loss: 0.1010 - val_accuracy: 0.9654\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 56s 2s/step - loss: 0.0325 - accuracy: 0.9876 - val_loss: 0.0999 - val_accuracy: 0.9697\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 73s 3s/step - loss: 0.0405 - accuracy: 0.9888 - val_loss: 0.9241 - val_accuracy: 0.8312\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 54s 2s/step - loss: 0.0313 - accuracy: 0.9888 - val_loss: 0.1788 - val_accuracy: 0.9459\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0567 - accuracy: 0.9832 - val_loss: 0.6205 - val_accuracy: 0.8247\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0321 - accuracy: 0.9854 - val_loss: 0.1766 - val_accuracy: 0.9697\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 0.3926 - val_accuracy: 0.9264\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0428 - accuracy: 0.9860 - val_loss: 0.4634 - val_accuracy: 0.8918\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 0.2168 - val_accuracy: 0.9351\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 49s 2s/step - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.0970 - val_accuracy: 0.9762\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0349 - accuracy: 0.9871 - val_loss: 0.3361 - val_accuracy: 0.9221\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0288 - accuracy: 0.9893 - val_loss: 0.0655 - val_accuracy: 0.9805\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0320 - accuracy: 0.9865 - val_loss: 0.2126 - val_accuracy: 0.9416\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0950 - accuracy: 0.9665 - val_loss: 1.5267 - val_accuracy: 0.6537\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0873 - accuracy: 0.9669 - val_loss: 0.2867 - val_accuracy: 0.9048\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 49s 2s/step - loss: 0.0383 - accuracy: 0.9854 - val_loss: 0.2833 - val_accuracy: 0.9069\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0384 - accuracy: 0.9871 - val_loss: 0.7229 - val_accuracy: 0.8268\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0377 - accuracy: 0.9854 - val_loss: 0.0923 - val_accuracy: 0.9740\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0442 - accuracy: 0.9837 - val_loss: 0.1740 - val_accuracy: 0.9437\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.0909 - val_accuracy: 0.9632\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.1297 - val_accuracy: 0.9610\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.0909 - val_accuracy: 0.9719\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0226 - accuracy: 0.9916 - val_loss: 0.1770 - val_accuracy: 0.9481\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0337 - accuracy: 0.9871 - val_loss: 0.1180 - val_accuracy: 0.9524\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.1535 - val_accuracy: 0.9567\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0292 - accuracy: 0.9876 - val_loss: 0.1723 - val_accuracy: 0.9459\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0276 - accuracy: 0.9894 - val_loss: 0.0996 - val_accuracy: 0.9697\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0165 - accuracy: 0.9933 - val_loss: 0.1157 - val_accuracy: 0.9675\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0281 - accuracy: 0.9893 - val_loss: 0.0848 - val_accuracy: 0.9740\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0293 - accuracy: 0.9876 - val_loss: 0.1121 - val_accuracy: 0.9719\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 51s 2s/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.1667 - val_accuracy: 0.9545\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.3257 - val_accuracy: 0.9307\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.1544 - val_accuracy: 0.9589\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0192 - accuracy: 0.9910 - val_loss: 0.1142 - val_accuracy: 0.9654\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 51s 2s/step - loss: 0.0259 - accuracy: 0.9910 - val_loss: 0.1600 - val_accuracy: 0.9545\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 55s 2s/step - loss: 0.0327 - accuracy: 0.9888 - val_loss: 0.1689 - val_accuracy: 0.9502\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.1143 - val_accuracy: 0.9697\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.0871 - val_accuracy: 0.9784\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0360 - accuracy: 0.9876 - val_loss: 0.2985 - val_accuracy: 0.9351\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 48s 2s/step - loss: 0.0279 - accuracy: 0.9899 - val_loss: 0.1215 - val_accuracy: 0.9567\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0277 - accuracy: 0.9899 - val_loss: 0.0724 - val_accuracy: 0.9762\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.1016 - val_accuracy: 0.9784\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 48s 2s/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.1840 - val_accuracy: 0.9416\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.1109 - val_accuracy: 0.9675\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 47s 2s/step - loss: 0.0476 - accuracy: 0.9860 - val_loss: 0.4599 - val_accuracy: 0.8377\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 52s 2s/step - loss: 0.0365 - accuracy: 0.9865 - val_loss: 0.2398 - val_accuracy: 0.9437\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 59s 2s/step - loss: 0.0496 - accuracy: 0.9854 - val_loss: 0.1590 - val_accuracy: 0.9589\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 56s 2s/step - loss: 0.0506 - accuracy: 0.9792 - val_loss: 3.6545 - val_accuracy: 0.5476\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 58s 2s/step - loss: 0.0690 - accuracy: 0.9770 - val_loss: 0.1454 - val_accuracy: 0.9610\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.0494 - accuracy: 0.9820 - val_loss: 0.1526 - val_accuracy: 0.9654\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 58s 2s/step - loss: 0.0570 - accuracy: 0.9820 - val_loss: 0.0705 - val_accuracy: 0.9654\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.0288 - accuracy: 0.9876 - val_loss: 0.1404 - val_accuracy: 0.9416\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 58s 2s/step - loss: 0.0188 - accuracy: 0.9927 - val_loss: 0.1476 - val_accuracy: 0.9610\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.0247 - accuracy: 0.9944 - val_loss: 0.6074 - val_accuracy: 0.8658\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 59s 2s/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.1019 - val_accuracy: 0.9719\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.0353 - accuracy: 0.9865 - val_loss: 0.1411 - val_accuracy: 0.9610\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.0400 - accuracy: 0.9865 - val_loss: 0.1980 - val_accuracy: 0.9502\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.0370 - accuracy: 0.9854 - val_loss: 0.1776 - val_accuracy: 0.9351\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.0281 - accuracy: 0.9894 - val_loss: 0.0861 - val_accuracy: 0.9805\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 58s 2s/step - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.1062 - val_accuracy: 0.9719\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 56s 2s/step - loss: 0.0192 - accuracy: 0.9921 - val_loss: 0.1209 - val_accuracy: 0.9740\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 58s 2s/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 0.5620 - val_accuracy: 0.8853\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.1086 - val_accuracy: 0.9654\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 54s 2s/step - loss: 0.0164 - accuracy: 0.9933 - val_loss: 0.0915 - val_accuracy: 0.9697\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 52s 2s/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.1282 - val_accuracy: 0.9675\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 55s 2s/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.1083 - val_accuracy: 0.9719\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 56s 2s/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0757 - val_accuracy: 0.9805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train the model\n",
    "\n",
    "\n",
    "history = model.fit(aug.flow(trainX, trainY, batch_size=batch_size), validation_data=(testX,testY), \n",
    "                       steps_per_epoch=len(trainX) // batch_size,\n",
    "                       epochs=epochs, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-498b6c3176db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d89329e4909d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yuz_tanima.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('yuz_tanima.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import cvlib as cv\n",
    "import imutils\n",
    "                    \n",
    "# load model\n",
    "model = load_model('yuz_tanima.model')\n",
    "\n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    "#w=webcam.get(3)\n",
    "#h=webcam.get(4)\n",
    "\n",
    "#yukarı_cizgi=int(1.35*(w/2.7))\n",
    "#asagı_cizgi=int(2.5*(w/3.3))\n",
    "\n",
    "#print (\"Red line y:\",str(yukarı_cizgi))\n",
    "#print (\"Blue line y:\", str(asagı_cizgi))\n",
    "\n",
    "cizgi_color=(40,40,160)\n",
    "cizgi2_color=(40,40,40)\n",
    "\n",
    "pt10=[700,150]\n",
    "pt11=[0,150]\n",
    "pts_L10 = np.array([pt10,pt11], np.int32)\n",
    "pts_L10 = pts_L10.reshape((-1,1,2))\n",
    "\n",
    "pt1=[700,130]\n",
    "pt2=[0,130]\n",
    "pts_L1 = np.array([pt1,pt2], np.int32)\n",
    "pts_L1 = pts_L1.reshape((-1,1,2))\n",
    "\n",
    "classes = ['man','woman']\n",
    "\n",
    "girenk=0;\n",
    "girene=0;\n",
    "a=0;\n",
    "\n",
    "\n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    "\n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "    frame = imutils.resize(frame, width=800)\n",
    "    frame=frame[:, 100:]\n",
    "\n",
    "    \n",
    "    frame=cv2.polylines(frame,[pts_L10],20,cizgi_color,thickness=2)\n",
    "    frame=cv2.polylines(frame,[pts_L1],False,cizgi2_color,thickness=2)\n",
    "\n",
    "    \n",
    "    # apply face detection\n",
    "    face, confidence = cv.detect_face(frame)\n",
    "\n",
    "\n",
    "    # loop through detected faces\n",
    "    for idx, f in enumerate(face):\n",
    "\n",
    "        # get corner points of face rectangle        \n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "        \n",
    "        # draw rectangle over face\n",
    "        cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "        cv2.circle(frame, ((startX+80), (startY+80)), 2, (0,0,255), 2)\n",
    "        \n",
    "        text = \"id\"+str(idx)\n",
    "        cv2.putText(frame, text, ((startX+80),(startY+80)),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.70, (0, 255, 255), 2)\n",
    "        \n",
    "        \n",
    "                \n",
    "        # crop the detected face region\n",
    "        face_crop = np.copy(frame[startY:endY,startX:endX])\n",
    "        if (face_crop.shape[0]) < 10 or (face_crop.shape[1]) < 10:\n",
    "            continue\n",
    "        # preprocessing for gender detection model\n",
    "        face_crop = cv2.resize(face_crop, (96,96))\n",
    "        face_crop = face_crop.astype(\"float\") / 255.0\n",
    "        face_crop = img_to_array(face_crop)\n",
    "        face_crop = np.expand_dims(face_crop, axis=0)\n",
    "\n",
    "        # apply gender detection on face\n",
    "        conf = model.predict(face_crop)[0] # model.predict return a 2D matrix, ex: [[9.9993384e-01 7.4850512e-05]]\n",
    "\n",
    "        # get label with max accuracy\n",
    "        idx = np.argmax(conf)\n",
    "        label = classes[idx]\n",
    "\n",
    "        label = \"{}: {:.2f}%\".format(label, conf[idx] * 100)\n",
    "\n",
    "       \n",
    "\n",
    "        # write label and confidence above face rectangle\n",
    "        cv2.putText(frame, label, (startX, startY),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        text = \"Giren Kadin Sayisi:\"+str(girenk)\n",
    "        cv2.putText(frame, text, (10,30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.70, (0, 255, 255), 2)\n",
    "        \n",
    "        \n",
    "        texta = \"Giren Erkek Sayisi:\"+str(girene)\n",
    "        cv2.putText(frame, texta, (10,60),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.70, (0, 255, 255), 2)\n",
    "        \n",
    "        \n",
    "        if (startY+80)>130 and  (startY+80)<pt10[1] and (startY+80)>pt1[1] and a==1:\n",
    "            a=0\n",
    "        if (startY+80)<pt1[1] and a==0:\n",
    "            if idx==1:\n",
    "                girenk+=1\n",
    "            if idx==0:\n",
    "                girene+=1\n",
    "            a=1\n",
    "            \n",
    "    # display output\n",
    "    cv2.imshow(\"Cinsiyet tespiti\", frame)\n",
    "\n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "      \n",
    "\n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
